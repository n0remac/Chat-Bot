{"id": "batch_req_6877e77b80688190833643f2be8727f7", "custom_id": "post-5897", "response": {"status_code": 400, "request_id": "a147cb99f709ceaa0e60ec3b12b79851", "body": {"error": {"message": "This model's maximum context length is 8192 tokens, however you requested 8406 tokens (8406 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.", "type": "invalid_request_error", "param": null, "code": null}}}, "error": null}
